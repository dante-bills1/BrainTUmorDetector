{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b67ec3-e87d-4742-a599-ae499c0ae36a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import gdown\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import yaml\n",
    "try:\n",
    "    with open (\"../config.yaml\", 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except Exception as e:\n",
    "    print('Error reading the config file')\n",
    "import sys\n",
    "\n",
    "# ML Models\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba27f81-66b9-4607-befb-cdbabe2120a4",
   "metadata": {},
   "source": [
    "# Models creation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20635056-e5e3-4947-94f9-0f7db7f2d42c",
   "metadata": {},
   "source": [
    "Please run the following cell to download and create database via python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058700c4-5ff4-4e69-9e42-230b2110c377",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting dataset and extracting it, please wait...\n",
      "\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=131ospwav2g6KKmG8q3iC1vf4mYk60y9O\n",
      "To: /home/juan/Documents/Ironhack/Week_9/data/brain_tumor_dataset.zip\n",
      "100%|████████████████████████████████████████| 156M/156M [00:09<00:00, 15.7MB/s]\n",
      "Dataset successfully created!\n"
     ]
    }
   ],
   "source": [
    "!python ../src/lib/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b6967-822b-40ec-90ee-68304ea6eca2",
   "metadata": {},
   "source": [
    "## Setting the paths to the images: creating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008c9a1-2a71-4779-8707-9f1e99fe1bfb",
   "metadata": {},
   "source": [
    "- Create 2 lists for each set: one with the path to the images, another with the label for each of those images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7ede0-dfb8-4afa-9be3-aa197e538d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "train_dir = config['data']+'Training/'\n",
    "test_dir = config['data']+'Testing/'\n",
    "\n",
    "train_paths = []\n",
    "train_labels = []\n",
    "\n",
    "for label in os.listdir(train_dir):\n",
    "    for image in os.listdir(train_dir+label):\n",
    "        train_paths.append(train_dir+label+'/'+image)\n",
    "        train_labels.append(label)\n",
    "\n",
    "train_paths, train_labels = shuffle(train_paths, train_labels)\n",
    "\n",
    "\n",
    "#Testing\n",
    "test_paths = []\n",
    "test_labels = []\n",
    "\n",
    "for label in os.listdir(test_dir):\n",
    "    for image in os.listdir(test_dir+label):\n",
    "        test_paths.append(test_dir+label+'/'+image)\n",
    "        test_labels.append(label)\n",
    "\n",
    "test_paths, test_labels = shuffle(test_paths, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a16ed8c-fab3-4d7c-9e5f-6faf1fa04682",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6713a1-a9fe-4c22-a5c0-cd690a65766e",
   "metadata": {},
   "source": [
    "- First function enhances brightness and contrast for each of the images with a random value between 0.8 and 1.2\n",
    "- Second function returns an array of the images (after using the first function to enhance them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92ee7a-0478-468a-b0ea-46583bb8ed40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_prep(image):\n",
    "    image = Image.fromarray(np.uint8(image))\n",
    "    image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8,1.2))\n",
    "    image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8,1.2))\n",
    "    image = np.array(image)/255.0\n",
    "    return image\n",
    "\n",
    "def open_images(paths, pic_size=128):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = load_img(path, target_size=(pic_size,pic_size))\n",
    "        image = image_prep(image)\n",
    "        images.append(image)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a72c8-2038-430f-9ed4-faaa101face7",
   "metadata": {},
   "source": [
    "Checking some of the pictures with matplotlib after applying the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826969ef-cf4b-4972-ae5a-b06e8293fc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = open_images(train_paths[50:59])\n",
    "labels = train_labels[50:59]\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "for x in range(1, 9):\n",
    "    fig.add_subplot(2, 4, x)\n",
    "    plt.axis('off')\n",
    "    plt.title(labels[x])\n",
    "    plt.imshow(images[x])\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e45c8-8a2a-48d8-acd4-82a4d596b8ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Label encoding and data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe52fd-ddb6-4d44-9292-f40acd75794e",
   "metadata": {},
   "source": [
    "- First function takes care of appending the image lable to the encode list.\n",
    "- Second function takes care of appending the image lable to the decode list (to be used later).\n",
    "- Third function generates the data for the model: yield is used to free up memory once the batch of images and labels is fed to it. First sets the paths, then uses the image augmentation function we defined before and encodes the image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0aa28-1cbc-4ebe-89d7-898b91b84020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = os.listdir(train_dir)\n",
    "\n",
    "def encode_label(labels):\n",
    "    encoded = []\n",
    "    for x in labels:\n",
    "        encoded.append(unique_labels.index(x))\n",
    "    return np.array(encoded)\n",
    "\n",
    "def decode_label(labels):\n",
    "    decoded = []\n",
    "    for x in labels:\n",
    "        decoded.append(unique_labels[x])\n",
    "    return np.array(decoded)\n",
    "\n",
    "def datagen(paths, labels, batch_size=12, epochs=1):\n",
    "    for _ in range(epochs):\n",
    "        for x in range(0, len(paths), batch_size):\n",
    "            batch_paths = paths[x:x+batch_size]\n",
    "            batch_images = open_images(batch_paths)\n",
    "            batch_labels = labels[x:x+batch_size]\n",
    "            batch_labels = encode_label(batch_labels)\n",
    "            yield batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466f912-9d37-49e4-87c1-e155e8fdb469",
   "metadata": {},
   "source": [
    "# Sequential model - from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c5ad9-0583-41ec-8616-73ed9220b540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bts = Sequential(name='Brain_Tumor_Scanner')\n",
    "\n",
    "# Layer 1\n",
    "bts.add(Conv2D(64,(7,7), input_shape=(128, 128, 3), padding='same', activation='relu'))\n",
    "bts.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 2\n",
    "bts.add(Conv2D(128,(7,7), padding='same', activation='relu'))\n",
    "bts.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 3\n",
    "bts.add(Conv2D(128,(7,7), padding='same', activation='relu'))\n",
    "bts.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 4\n",
    "bts.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
    "bts.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 5\n",
    "bts.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
    "bts.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Layer 6\n",
    "bts.add(Conv2D(256,(7,7), padding='same', activation='relu'))\n",
    "bts.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# Connect layers\n",
    "bts.add(Flatten())\n",
    "bts.add(Dropout(0.3))\n",
    "bts.add(Dense(128, activation='relu'))\n",
    "bts.add(Dropout(0.2))\n",
    "bts.add(Dense(len(unique_labels), activation='softmax'))\n",
    "\n",
    "\n",
    "bts.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "bts.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb219b5-9a5b-47e1-822f-4cf8852f3de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps = int(len(train_paths)/batch_size)\n",
    "epochs = 12\n",
    "bts_mcp = ModelCheckpoint(filepath = config['models']+'bts_weights.h5', monitor = 'sparse_categorical_accuracy', \n",
    "                      save_best_only = True, verbose = 2)\n",
    "bts_es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 3, verbose = 1)\n",
    "bts_rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 2, verbose = 1)\n",
    "\n",
    "\n",
    "bts_history = bts.fit(datagen(train_paths, train_labels, batch_size=batch_size, epochs=epochs),\n",
    "                    epochs=epochs, steps_per_epoch=steps, callbacks=[bts_mcp, bts_es, bts_rlr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af0eef-feb3-4f09-befe-4cdd21871e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bts.save(config['models']+'bts.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951775a-e91f-4c8c-b386-92b0be87eca0",
   "metadata": {},
   "source": [
    "### Visualization of the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b7fef-e717-44a4-bee0-1de5e1155c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.grid(True)\n",
    "plt.plot(bts_history.history['sparse_categorical_accuracy'], '.g-', linewidth=2)\n",
    "plt.plot(bts_history.history['loss'], '.r-', linewidth=2)\n",
    "plt.title('Model Training History - Sequential')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(epochs)])\n",
    "plt.legend(['Accuracy', 'Loss'], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0d620-92ad-464a-bf2f-e5513e3ecb1d",
   "metadata": {},
   "source": [
    "## Generating the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba19aaa-9f4b-4815-853e-269cd1a47215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = int(len(test_paths)/batch_size)\n",
    "y_pred_bts = []\n",
    "y_true_bts = []\n",
    "for x,y in tqdm(datagen(test_paths, test_labels, batch_size=batch_size, epochs=1), total=steps):\n",
    "    pred = bts.predict(x)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    for i in decode_label(pred):\n",
    "        y_pred_bts.append(i)\n",
    "    for i in decode_label(y):\n",
    "        y_true_bts.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac58b3f9-4681-43e7-9fef-4ac10118416a",
   "metadata": {},
   "source": [
    "## Model performance: Classification Report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e496fa-712d-4667-a51c-f84c65e24810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_bts, y_pred_bts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361abdc-c5a6-4859-b372-3bce1a9cb054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Confusion matrix\n",
    "cm_bts = confusion_matrix(y_true_bts, y_pred_bts)\n",
    "display_cm_bts = ConfusionMatrixDisplay(cm_bts, display_labels=m_labels)\n",
    "display_cm_bts.plot()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(config['pics']+'confusion_matrix_bts.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397278d-2d1d-44d1-9f93-56c91134ee2f",
   "metadata": {},
   "source": [
    "Our model has a really good performance. We will check another model created from transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1846dd-b336-4779-97a7-984a98808767",
   "metadata": {},
   "source": [
    "# Transfer Learning model: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7418f39-099d-4fa6-8eae-3d6f78b34ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import VGG16 - Very Deep Convolutional Networks for Large-Scale Image Recognition\n",
    "base_model = VGG16(input_shape=(128,128,3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Set all layers to non-trainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Set the last vgg16 block to trainable\n",
    "base_model.layers[-2].trainable = True\n",
    "base_model.layers[-3].trainable = True\n",
    "base_model.layers[-4].trainable = True\n",
    "\n",
    "trl = Sequential(name='Brain_Tumor_Scanner_TRL')\n",
    "trl.add(Input(shape=(128,128,3)))\n",
    "trl.add(base_model)\n",
    "trl.add(Flatten())\n",
    "trl.add(Dropout(0.3))\n",
    "trl.add(Dense(128, activation='relu'))\n",
    "trl.add(Dropout(0.2))\n",
    "trl.add(Dense(len(unique_labels), activation='softmax'))\n",
    "\n",
    "trl.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb046c39-be99-4564-b4ba-c5998d2b010e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951989f-c80a-46ab-9e21-b2683a8bb2c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "steps = int(len(train_paths)/batch_size)\n",
    "epochs = 12\n",
    "trl_mcp = ModelCheckpoint(filepath = config['models']+'trl_weights.h5', monitor = 'sparse_categorical_accuracy', \n",
    "                      save_best_only = True, verbose = 2)\n",
    "trl_es = EarlyStopping(monitor = 'loss', min_delta = 1e-10, patience = 3, verbose = 1)\n",
    "trl_rlr = ReduceLROnPlateau(monitor = 'loss', factor = 0.2, patience = 2, verbose = 1)\n",
    "\n",
    "\n",
    "trl_history = trl.fit(datagen(train_paths, train_labels, batch_size=batch_size, epochs=epochs),\n",
    "                    epochs=epochs, steps_per_epoch=steps, callbacks=[trl_mcp, trl_es, trl_rlr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20368c18-e42c-47ea-b38d-107fe8de75fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trl.save(config['models']+'trl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46825cdb-6bd7-4f3e-85cd-601ed18fb2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.grid(True)\n",
    "plt.plot(trl_history.history['sparse_categorical_accuracy'], '.g-', linewidth=2)\n",
    "plt.plot(trl_history.history['loss'], '.r-', linewidth=2)\n",
    "plt.title('Model Training History - Transfer Learning')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(epochs)])\n",
    "plt.legend(['Accuracy', 'Loss'], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d3d81f-bd75-45c9-93dc-8e140d00a84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "steps = int(len(test_paths)/batch_size)\n",
    "y_pred_trl = []\n",
    "y_true_trl = []\n",
    "for x,y in tqdm(datagen(test_paths, test_labels, batch_size=batch_size, epochs=1), total=steps):\n",
    "    pred = trl.predict(x)\n",
    "    pred = np.argmax(pred, axis=-1)\n",
    "    for i in decode_label(pred):\n",
    "        y_pred_trl.append(i)\n",
    "    for i in decode_label(y):\n",
    "        y_true_trl.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafa6fc-3e54-489a-82d0-1706f3f55665",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5532d97-96f0-49dc-9fc1-d84d76b54616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true_trl, y_pred_trl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50a8fd-13a4-4ebf-86b3-2ab8ba330c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_trl = confusion_matrix(y_true_trl, y_pred_trl)\n",
    "display_cm_trl = ConfusionMatrixDisplay(cm_trl, display_labels=m_labels)\n",
    "display_cm_trl.plot()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(config['pics']+'confusion_matrix_trl.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ffa95-58c2-4d8b-9b24-c6bff982d0df",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a741e53-ce78-4454-857b-b28c0927daed",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad340c9-fc14-4238-bf5d-a99e3321a1a8",
   "metadata": {},
   "source": [
    "Make sure to check the unique_labels list and the index order: this will assign an index number to each of the classes, and may change with each run since we are shuffling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6ef72-5601-4eef-93eb-f4acca9f1a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984a4cd-ea16-4c77-b011-b699f3a741f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conclusion(number):\n",
    "    if number==0:\n",
    "        return 'Tumor - Glioma'\n",
    "    elif number ==3:\n",
    "        return 'Tumor - Meningioma'\n",
    "    elif number == 1:\n",
    "        return 'Not a tumor'\n",
    "    elif number == 2:\n",
    "        return 'Tumor - pituitary'\n",
    "    else:\n",
    "        return 'Sorry, not clear'\n",
    "\n",
    "def diagnosis(image, model):\n",
    "    img = Image.open(image)\n",
    "    x = np.array(img.resize((128,128)))\n",
    "    x = x.reshape(1,128,128,3)\n",
    "    res = model.predict_on_batch(x)\n",
    "    classification = np.where(res == np.amax(res))[1][0]\n",
    "    imshow(img)\n",
    "    print(conclusion(classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5f184-07b0-446c-a0c0-2bd4207753dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = config['data']+'Testing/notumor/Te-no_0052.jpg'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fecf0bdb-bb85-4891-8b9d-46899608d341",
   "metadata": {
    "tags": []
   },
   "source": [
    "diagnosis(image, bts)\n",
    "diagnosis(image, trl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8d399-453e-4d6b-98f3-a5184e6860c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = config['data']+'Testing/meningioma/Te-me_0015.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1aee71-5f47-4483-8229-83ac5f228fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diagnosis(image, bts)\n",
    "diagnosis(image, trl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4d701b-f143-4a80-8d6d-f624d236d801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = config['pics']+'diagnose/pituitary1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73fb6c-9bdf-42f2-890e-21d43d7c3dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diagnosis(image, bts)\n",
    "diagnosis(image, trl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dba459-420d-40ce-9a3f-028be11fedeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = config['data']+'Testing/glioma/Te-gl_0036.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddd895-53d8-4e37-8e15-2f8053052dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diagnosis(image, bts)\n",
    "diagnosis(image, trl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee7920-f971-4465-bac7-d5e09f87cb63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
